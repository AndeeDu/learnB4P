---
title: "01 - Introduction"
author: "Stefano Coretta"
format:
  mono-light-revealjs:
    theme: [default, custom.scss]
    history: false
filters:
  - tachyonsextra
execute: 
  echo: true
  
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
theme_set(theme_light())
library(coretta2018itapol)
library(brms)
```

## Schedule: Day 1

| time        | topic                     |
| ----------- | ------------------------- |
| 10.00-11.15 | 01 Introduction           |
| 11.15-11.30 | BREAK                     |
| 11.30-12.30 | 02 Priors                 |
| 12.30-13.30 | LUNCH                     |
| 13.30-14.45 | 03 Categorical predictors |
| 14.45-15.00 | BREAK                     |
| 15.00-16.00 | 04 Interactions           |
| 16.00-17.00 | Q&A                       |

## Schedule: Day 2

| time        | topic                   |
| ----------- | ----------------------- |
| 10.00-11.15 | 05 Numeric predictors   |
| 11.15-11.30 | BREAK                   |
| 11.30-12.30 | 06 Multilevel effects   |
| 12.30-13.30 | LUNCH                   |
| 13.30-14.45 | 07 Practice             |
| 14.45-15.00 | BREAK                   |
| 15.00-16.00 | 08 Sensitivity analysis |
| 16.00-17.00 | Q&A                     |

## Statistical modelling

![From McElreath 2019](img/models.png)

## Statistical inference

![The inference process](img/inference.png)


## Two frameworks of inference

::: {layout-ncol="2"}
![](img/np.jpg){fig-align="center" width="248"}

![](img/Thomas_Bayes.gif){fig-align="center" width="373"}
:::


## Frequentist framework

::: box-note
- Neyman-Pearson's Null Hypothesis Significance Testing (NHST).

- Based on frequentist interpretation of probabilities as **long-run occurrences of events**.

- Output:
  - **Point estimates** of predictors' parameters (with standard error).
  -   *p*-values.
:::


## Bayesian framework

::: box-note
- Bayesian inference.

- Based on the Bayesian interpretation of probabilities as **degree of belief in the occurrence of events**.

-  Output:
  - **Probability distributions** of model's parameters.
:::


## Bayesian regression: basics

::: box-note
-   R package brms.

-   Same syntax as lme4.

-   One function to fit many types of regression models: `brm()`.
:::


## Example data: background

::: box-note
- Effect of consonant voicing on preceding vowel duration in Italian and Polish.

- pVCV words (/a, o, u/, /t, d, k, g/).

- 11 Italian speakers, 6 Polish speakers. 5 repetitions.
:::

## Example data: the data frame

```{r}
#| label: data

library(coretta2018itapol)
data("token_measures")

token_measures
```

## Vowel duration and consonant voicing

```{r}
#| label: vdur-strip
#| echo: false

token_measures |> 
  ggplot(aes(c2_phonation, v1_duration)) +
  geom_jitter(width = 0.2, alpha = 0.1) +
  stat_summary(fun.data = "mean_cl_boot", colour = "purple") +
  facet_grid(cols = vars(language))
```

## Vowel duration

```{r}
#| label: vdur-dens
#| echo: false

token_measures |> 
ggplot(aes(v1_duration)) +
geom_density(fill = "purple", alpha = 0.5) +
geom_rug(alpha = 0.1)
```

## Gaussian model of vowel duration

$$
\begin{align}
dur & \sim Gaussian(\mu, \sigma)
\end{align}
$$

-   $dur$ is vowel duration

-   $\sim$ means "is distributed/generated according to".

-   $Gaussian(\mu, \sigma)$ a Gaussian distribution with mean $\mu$ and standard deviation $\sigma$.

## Fit the model with brms

```{r}
#| label: m-1

m_1 <- brm(
  v1_duration ~ 1,
  family = gaussian,
  data = token_measures,
  cores = 4,
  file = "data/cache/m_1",
)
```

## Model summary

```{r}
#| label: m-1-summary

summary(m_1)
```

## Model summary: 80% CrIs

```{r}
#| label: m-1-summary-0.8

summary(m_1, prob = 0.8)
```

## Plot posterior probability distributions

```{r}
#| label: m-1-plot

plot(m_1, combo = c("dens", "trace"))
```

## Diagnostics: posterior predictive checks

```{r}
#| label: m-1-pp-check
pp_check(m_1, ndraws = 50)
```

## Log-normal model of vowel duration

$$
\begin{align}
dur & \sim LogNormal(\mu, \sigma)
\end{align}
$$

. . .

$$
\begin{align}
log(dur) & \sim Gaussian(\mu_1, \sigma_1)
\end{align}
$$

## Fit the log-normal model

```{r}
#| label: m-2

m_2 <- brm(
  v1_duration ~ 1,
  family = lognormal,
  data = token_measures,
  cores = 4,
  file = "data/cache/m_2",
)
```

## Model summary

```{r}
#| label: m-2-summary

summary(m_2, prob = 0.8)
```

## Posterior predictive checks

```{r}
#| label: m-2-pp-check

pp_check(m_2, ndraws = 50)
```
