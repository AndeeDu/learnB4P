{
  "hash": "e4e9cfc98902cd032301b6d88ec13e5e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"04 - Interactions\"\nauthor: \"Stefano Coretta\"\nformat:\n  mono-light-revealjs:\n    theme: [default, custom.scss]\n    history: false\nfilters:\n  - tachyonsextra\nexecute:\n  echo: true\nknitr:\n  opts_chunk: \n    fig-align: center\n---\n\n\n\n\n## Set order of levels\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntoken_measures <- token_measures |> \n  mutate(\n    c2_phonation = factor(c2_phonation, levels = c(\"voiceless\", \"voiced\"))\n  )\n```\n:::\n\n\n\n## Vowel duration by voicing and language\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](04_interactions_files/figure-revealjs/vdur-voi-lang-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## Categorical predictors: interactions\n\n$$\n\\begin{align}\nvdur_i & \\sim LogNormal(\\mu_i, \\sigma)\\\\\n\\mu_i & = \\beta_{voicing[i], language[i]}\\\\\n\\beta_{jw} & \\sim Gaussian(\\mu_j, \\sigma_j) & , \\text{for } j = 1..2\\\\\n &  &  w = 1..2\\\\\n\\sigma & \\sim Cauchy_{+}(0, \\sigma_3)\\\\\n\\end{align}\n$$\n\n## Get default priors: indexing\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nget_prior(\n  v1_duration ~ 0 + c2_phonation:language,\n  family = lognormal,\n  data = token_measures\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                prior class                                  coef group resp\n               (flat)     b                                                 \n               (flat)     b    c2_phonationvoiced:languageItalian           \n               (flat)     b     c2_phonationvoiced:languagePolish           \n               (flat)     b c2_phonationvoiceless:languageItalian           \n               (flat)     b  c2_phonationvoiceless:languagePolish           \n student_t(3, 0, 2.5) sigma                                                 \n dpar nlpar lb ub       source\n                       default\n                  (vectorized)\n                  (vectorized)\n                  (vectorized)\n                  (vectorized)\n             0         default\n```\n\n\n:::\n:::\n\n\n## Priors\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_5_priors <- c(\n  # Prior for the four `b` coefficients\n  prior(normal(4.45, 0.55), class = b),\n  # Prior for sigma\n  prior(normal(0, 0.1), class = sigma)\n)\n\nm_5_priors\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              prior class coef group resp dpar nlpar   lb   ub source\n normal(4.45, 0.55)     b                            <NA> <NA>   user\n     normal(0, 0.1) sigma                            <NA> <NA>   user\n```\n\n\n:::\n:::\n\n\n## Prior predictive checks\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmy_seed <- 1382\n\nm_5_priorpp <- brm(\n  v1_duration ~ 0 + c2_phonation:language,\n  data = token_measures,\n  family = lognormal,\n  prior = m_5_priors,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = my_seed,\n  file = \"data/cache/m_5_priorpp\"\n)\n```\n:::\n\n\n## Prior predictive plots\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nconditional_effects(m_5_priorpp, effects = \"language:c2_phonation\")\n```\n\n::: {.cell-output-display}\n![](04_interactions_files/figure-revealjs/m-5-prior-pp-plot-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## Fit the model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_5 <- brm(\n  v1_duration ~ 0 + c2_phonation:language,\n  data = token_measures,\n  family = lognormal,\n  prior = m_5_priors,\n  seed = my_seed,\n  cores = 4,\n  file = \"data/cache/m_5\"\n)\n```\n:::\n\n\n## Model summary\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(m_5, prob = 0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: lognormal \n  Links: mu = identity; sigma = identity \nFormula: v1_duration ~ 0 + c2_phonation:language \n   Data: token_measures (Number of observations: 1342) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                                      Estimate Est.Error l-80% CI u-80% CI Rhat\nc2_phonationvoiceless:languageItalian     4.67      0.01     4.65     4.68 1.00\nc2_phonationvoiced:languageItalian        4.78      0.01     4.76     4.79 1.00\nc2_phonationvoiceless:languagePolish      4.30      0.02     4.27     4.32 1.00\nc2_phonationvoiced:languagePolish         4.39      0.02     4.37     4.42 1.00\n                                      Bulk_ESS Tail_ESS\nc2_phonationvoiceless:languageItalian     5246     3360\nc2_phonationvoiced:languageItalian        5482     3145\nc2_phonationvoiceless:languagePolish      4966     3196\nc2_phonationvoiced:languagePolish         4724     3314\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-80% CI u-80% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.27      0.01     0.26     0.28 1.00     5045     3059\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n## Posterior probability distributions: outcome (vowel duration)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nconditional_effects(m_5, effects = \"language:c2_phonation\")\n```\n\n::: {.cell-output-display}\n![](04_interactions_files/figure-revealjs/m-5-cond-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## Posterior probability distribution: difference of vowel duration\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(marginaleffects)\n\n# In milliseconds\navg_comparisons(m_5, variables = \"c2_phonation\", by = \"language\", conf_level = 0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n         Term                       Contrast language Estimate 10.0 % 90.0 %\n c2_phonation mean(voiced) - mean(voiceless)  Italian    12.74  10.01   15.3\n c2_phonation mean(voiced) - mean(voiceless)  Polish      7.65   5.06   10.3\n\nColumns: term, contrast, language, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx \nType:  response \n```\n\n\n:::\n:::\n\n\n## Posterior probability distribution: difference of vowel duration\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# As ratio\navg_comparisons(m_5, variables = \"c2_phonation\", by = \"language\", conf_level = 0.8, comparison = \"ratio\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n         Term                       Contrast language Estimate 10.0 % 90.0 %\n c2_phonation mean(voiced) / mean(voiceless)  Italian     1.12   1.09   1.14\n c2_phonation mean(voiced) / mean(voiceless)  Polish      1.10   1.07   1.14\n\nColumns: term, contrast, language, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx \nType:  response \n```\n\n\n:::\n:::\n\n\n## Posterior probability distribution: difference of difference\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\navg_comparisons(m_5, variables = \"c2_phonation\", by = \"language\", conf_level = 0.8, comparison = \"ratio\", hypothesis = \"b2 = b1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  Term Estimate  10.0 % 90.0 %\n b2=b1  -0.0143 -0.0577 0.0296\n\nColumns: term, estimate, conf.low, conf.high \nType:  response \n```\n\n\n:::\n:::\n\n\n## Reporting\n\nWe fitted a Bayesian regression in R (R Core 2024) with brms (BÃ¼rkner 2017, 2018, 2021) to vowel duration using a log-normal distribution as the distribution family of the outcome. As predictors, we included C2 voicing (voiceless vs voiced) and language (Italian vs Polish). The predictors were coded using indexing (i.e. by suppressing the model's intercept).\n\nAccording to the model, vowels followed by voiced stops are 10-15 ms longer in Italian and 5-10 ms longer in Polish, at 80% confidence. As a ratio of the duration of vowels followed by voiceless stops, vowels followed by voiced stops are 1.09-1.14 times longer in Italian and 1.07-1.14 times longer in Polish, at 80% probability. While the raw difference in milliseconds is different in Italian vs Polish, the ratio difference are very similar.\n\nAt 80% confidence, the difference in voicing effect ratio between Italian and Polish is between -0.06 and 0.03. This suggests that if there is a difference between the two language, it could be negative or positive although negative values are more likely.",
    "supporting": [
      "04_interactions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}