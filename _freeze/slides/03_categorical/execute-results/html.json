{
  "hash": "12c6d9a01f8c135bca1f39d5d58b8dac",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"03 - Categorical predictors\"\nauthor: \"Stefano Coretta\"\nformat:\n  mono-light-revealjs:\n    theme: [default, custom.scss]\n    history: false\nfilters:\n  - tachyonsextra\nexecute:\n  echo: true\nknitr:\n  opts_chunk: \n    fig-align: center\n---\n\n\n\n\n## Vowel duration by voicing\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03_categorical_files/figure-revealjs/vdur-voi-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## Categorical predictors: treatment contrasts (default)\n\n$$\n\\begin{align}\nvdur_i & \\sim LogNormal(\\mu, \\sigma)\\\\\n\\mu & = \\beta_0 + \\beta_1 \\cdot \\text{voiceless}_i \\\\\n\\beta_0 & \\sim Gaussian(\\mu_0, \\sigma_0)\\\\\n\\beta_1 & \\sim Gaussian(\\mu_1, \\sigma_1)\\\\\n\\sigma & \\sim Cauchy_{+}(0, \\sigma_2)\\\\\n\\end{align}\n$$\n\n## Get default priors\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nget_prior(\n  v1_duration ~ c2_phonation,\n  family = lognormal,\n  data = token_measures\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  prior     class                  coef group resp dpar nlpar\n                 (flat)         b                                            \n                 (flat)         b c2_phonationvoiceless                      \n student_t(3, 4.6, 2.5) Intercept                                            \n   student_t(3, 0, 2.5)     sigma                                            \n lb ub       source\n            default\n       (vectorized)\n            default\n  0         default\n```\n\n\n:::\n:::\n\n\n## Categorical predictors: indexing\n\n$$\n\\begin{align}\nvdur_i & \\sim LogNormal(\\mu_i, \\sigma)\\\\\n\\mu_i & = \\beta_{voicing[i]}\\\\\n\\beta_j & \\sim Gaussian(\\mu_j, \\sigma_j) & , \\text{for } j = 1..2\\\\\n\\sigma & \\sim Cauchy_{+}(0, \\sigma_3)\\\\\n\\end{align}\n$$\n\n## Get default priors: indexing\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nget_prior(\n  v1_duration ~ 0 + c2_phonation,\n  family = lognormal,\n  data = token_measures\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                prior class                  coef group resp dpar nlpar lb ub\n               (flat)     b                                                  \n               (flat)     b    c2_phonationvoiced                            \n               (flat)     b c2_phonationvoiceless                            \n student_t(3, 0, 2.5) sigma                                              0   \n       source\n      default\n (vectorized)\n (vectorized)\n      default\n```\n\n\n:::\n:::\n\n\n## Priors\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_4_priors <- c(\n  # Prior for both `b` coefficients\n  prior(normal(4.45, 0.55), class = b),\n  prior(normal(0, 0.1), class = sigma)\n)\n\nm_4_priors\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              prior class coef group resp dpar nlpar   lb   ub source\n normal(4.45, 0.55)     b                            <NA> <NA>   user\n     normal(0, 0.1) sigma                            <NA> <NA>   user\n```\n\n\n:::\n:::\n\n\n## Prior predictive checks\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmy_seed <- 9682\n\nm_4_priorpp <- brm(\n  v1_duration ~ 0 + c2_phonation,\n  data = token_measures,\n  family = lognormal,\n  prior = m_4_priors,\n  sample_prior = \"only\",\n  cores = 4,\n  seed = my_seed,\n  file = \"data/cache/m_4_priorpp\"\n)\n```\n:::\n\n\n## Prior predictive plots\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nconditional_effects(m_4_priorpp)\n```\n\n::: {.cell-output-display}\n![](03_categorical_files/figure-revealjs/m-4-prior-pp-plot-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## Fit the model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_4 <- brm(\n  v1_duration ~ 0 + c2_phonation,\n  data = token_measures,\n  family = lognormal,\n  prior = m_4_priors,\n  seed = my_seed,\n  cores = 4,\n  file = \"data/cache/m_4\"\n)\n```\n:::\n\n\n## Model summary\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(m_4, prob = 0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: lognormal \n  Links: mu = identity; sigma = identity \nFormula: v1_duration ~ 0 + c2_phonation \n   Data: token_measures (Number of observations: 1342) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                      Estimate Est.Error l-80% CI u-80% CI Rhat Bulk_ESS\nc2_phonationvoiced        4.65      0.01     4.63     4.66 1.00     4593\nc2_phonationvoiceless     4.54      0.01     4.53     4.56 1.00     4526\n                      Tail_ESS\nc2_phonationvoiced        3242\nc2_phonationvoiceless     3027\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-80% CI u-80% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.32      0.01     0.31     0.33 1.00     4205     2982\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n## Posterior probability distributions: outcome (vowel duration)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nconditional_effects(m_4)\n```\n\n::: {.cell-output-display}\n![](03_categorical_files/figure-revealjs/m-4-cond-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## Posterior probability distribution: difference of vowel duration\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(marginaleffects)\n\navg_comparisons(m_4, conf_level = 0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n         Term                       Contrast Estimate 10.0 % 90.0 %\n c2_phonation mean(voiceless) - mean(voiced)    -10.9  -13.2  -8.63\n\nColumns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx \nType:  response \n```\n\n\n:::\n:::\n\n\n## Posterior probability distributions\n\n| Posteriors | package         | function                |\n|------------|-----------------|-------------------------|\n| Outcome    | brms            | `conditional_effects()` |\n| Difference | marginaleffects | `avg_comparisons()`     |\n",
    "supporting": [
      "03_categorical_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}